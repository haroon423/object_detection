{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "714d5fb5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'YOLO_V8_TINY_WEIGHTS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m TRAIN_YOLO_TINY \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m YOLO_TYPE \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolov8\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 22\u001b[0m     Darknet_weights \u001b[38;5;241m=\u001b[39m \u001b[43mYOLO_V8_TINY_WEIGHTS\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m TRAIN_YOLO_TINY \u001b[38;5;28;01melse\u001b[39;00m YOLO_V8_WEIGHTS\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m YOLO_TYPE \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolov8\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     24\u001b[0m     Darknet_weights \u001b[38;5;241m=\u001b[39m YOLO_V8_TINY_WEIGHTS \u001b[38;5;28;01mif\u001b[39;00m TRAIN_YOLO_TINY \u001b[38;5;28;01melse\u001b[39;00m YOLO_V8_WEIGHTS\n",
      "\u001b[1;31mNameError\u001b[0m: name 'YOLO_V8_TINY_WEIGHTS' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from yolov8.dataset import Dataset\n",
    "from yolov8.utils import load_yolo_weights\n",
    "from yolov8.configs import *\n",
    "from evaluate_mAP import get_mAP\n",
    "import torch.onnx\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "YOLO_TYPE = \"yolov8\"\n",
    "TRAIN_YOLO_TINY = True\n",
    "\n",
    "if YOLO_TYPE == \"yolov8\":\n",
    "    Darknet_weights = YOLO_V8_TINY_WEIGHTS if TRAIN_YOLO_TINY else YOLO_V8_WEIGHTS\n",
    "elif YOLO_TYPE == \"yolov8\":\n",
    "    Darknet_weights = YOLO_V8_TINY_WEIGHTS if TRAIN_YOLO_TINY else YOLO_V8_WEIGHTS\n",
    "if TRAIN_YOLO_TINY:\n",
    "    TRAIN_MODEL_NAME += \"_Tiny\"\n",
    "\n",
    "    def main():\n",
    "        global TRAIN_FROM_CHECKPOINT\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        try:\n",
    "            torch.cuda.set_memory_allocated(device, True)\n",
    "        except RuntimeError:\n",
    "            pass\n",
    "\n",
    "    if os.path.exists(TRAIN_LOGDIR):\n",
    "        shutil.rmtree(TRAIN_LOGDIR)\n",
    "    writer = SummaryWriter(TRAIN_LOGDIR)\n",
    "train_dataset = YourDataset('C:/Users/Haroon/Desktop/Fortnite_clean_dataset/train', transform=transforms.Compose([...]))  \n",
    "test_dataset = YourDataset('C:/Users/Haroon/Desktop/Fortnite_clean_dataset/test', transform=transforms.Compose([...])) \n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "steps_per_epoch = len(train_loader)\n",
    "global_steps = 1\n",
    "warmup_steps = TRAIN_WARMUP_EPOCHS * steps_per_epoch\n",
    "total_steps = TRAIN_EPOCHS * steps_per_epoch\n",
    "\n",
    "if TRAIN_TRANSFER:\n",
    "    Darknet = YourYoloModel(input_size=YOLO_INPUT_SIZE, num_classes=NUM_CLASSES)\n",
    "    Darknet.load_darknet_weights(Darknet_weights)\n",
    "\n",
    "yolo = YourYoloModel(input_size=YOLO_INPUT_SIZE, num_classes=NUM_CLASSES)\n",
    "if TRAIN_FROM_CHECKPOINT:\n",
    "    try:\n",
    "        yolo.load_state_dict(torch.load(TRAIN_FROM_CHECKPOINT))\n",
    "    except ValueError:\n",
    "        print(\"Shapes are incompatible, transferring Darknet weights\")\n",
    "        TRAIN_FROM_CHECKPOINT = False\n",
    "\n",
    "if TRAIN_TRANSFER and not TRAIN_FROM_CHECKPOINT:\n",
    "    for i, (name, layer) in enumerate(Darknet.named_children()):\n",
    "        if hasattr(layer, 'weight'):\n",
    "            layer_weights = layer.weight\n",
    "            if layer_weights.numel() > 0:\n",
    "                try:\n",
    "                    yolo_state_dict = yolo.state_dict()\n",
    "                    yolo_state_dict[name + '.weight'] = layer_weights\n",
    "                    yolo.load_state_dict(yolo_state_dict)\n",
    "                except Exception as e:\n",
    "                    print(\"Skipping layer {}: {}\".format(name, str(e)))\n",
    "\n",
    "optimizer = optim.Adam(yolo.parameters())\n",
    "\n",
    "criterion_giou = nn.MSELoss()  \n",
    "criterion_conf = nn.BCELoss()  \n",
    "criterion_prob = nn.BCELoss()  \n",
    "\n",
    "def train_step(image_data, target):\n",
    "    optimizer.zero_grad()  \n",
    "\n",
    "    pred_result = yolo(image_data)  \n",
    "\n",
    "    giou_loss = conf_loss = prob_loss = 0\n",
    "\n",
    "    grid = 3 if not TRAIN_YOLO_TINY else 2\n",
    "    for i in range(grid):\n",
    "        conv, pred = pred_result[i * 2], pred_result[i * 2 + 1]\n",
    "        loss_items = compute_loss(pred, conv, *target[i], i, CLASSES=TRAIN_CLASSES)\n",
    "\n",
    "        giou_loss += criterion_giou(loss_items[0], torch.zeros_like(loss_items[0]))\n",
    "        conf_loss += criterion_conf(loss_items[1], torch.zeros_like(loss_items[1]))\n",
    "        prob_loss += criterion_prob(loss_items[2], torch.zeros_like(loss_items[2]))\n",
    "\n",
    "    total_loss = giou_loss + conf_loss + prob_loss\n",
    "\n",
    "    total_loss.backward()  \n",
    "    optimizer.step()\n",
    "    lr_scheduler = CosineAnnealingLR(optimizer, T_max=total_steps - warmup_steps, eta_min=TRAIN_LR_END)\n",
    "\n",
    "global_steps += 1\n",
    "if global_steps < warmup_steps:\n",
    "    lr = global_steps / warmup_steps * TRAIN_LR_INIT\n",
    "else:\n",
    "    lr = TRAIN_LR_END + 0.5 * (TRAIN_LR_INIT - TRAIN_LR_END) * (1 + torch.cos((global_steps - warmup_steps) / (total_steps - warmup_steps) * 3.14159265359))\n",
    "lr_scheduler.step(global_steps)\n",
    "writer = SummaryWriter(TRAIN_LOGDIR)\n",
    "\n",
    "with writer.as_default():\n",
    "    writer.add_scalar(\"lr\", optimizer.param_groups[0]['lr'], global_steps)\n",
    "    writer.add_scalar(\"loss/total_loss\", total_loss, global_steps)\n",
    "    writer.add_scalar(\"loss/giou_loss\", giou_loss, global_steps)\n",
    "    writer.add_scalar(\"loss/conf_loss\", conf_loss, global_steps)\n",
    "    writer.add_scalar(\"loss/prob_loss\", prob_loss, global_steps)\n",
    "writer.close()\n",
    "validate_writer = SummaryWriter(TRAIN_LOGDIR + \"_validate\")\n",
    "\n",
    "with validate_writer.as_default():\n",
    "    writer.add_scalar(\"validate_loss/giou_val\", giou_loss/count, epoch)\n",
    "    writer.add_scalar(\"validate_loss/conf_val\", conf_loss/count, epoch)\n",
    "    writer.add_scalar(\"validate_loss/prob_val\", prob_loss/count, epoch)\n",
    "    writer.add_scalar(\"validate_loss/total_val\", total_loss/count, epoch)\n",
    "validate_writer.close()\n",
    "\n",
    "mAP_model = Create_Yolo(input_size=YOLO_INPUT_SIZE, CLASSES=TRAIN_CLASSES)\n",
    "best_val_loss = 1000\n",
    "\n",
    "writer = SummaryWriter(TRAIN_LOGDIR)\n",
    "\n",
    "for epoch in range(TRAIN_EPOCHS):\n",
    "    for image_data, target in trainset:\n",
    "        results = train_step(image_data, target)\n",
    "        cur_step = results[0] % steps_per_epoch\n",
    "        print(\"epoch:{:2.0f} step:{:5.0f}/{}, lr:{:.6f}, giou_loss:{:7.2f}, conf_loss:{:7.2f}, prob_loss:{:7.2f}, total_loss:{:7.2f}\"\n",
    "              .format(epoch, cur_step, steps_per_epoch, results[1], results[2], results[3], results[4], results[5]))\n",
    "\n",
    "    if len(testset) == 0:\n",
    "        print(\"configure TEST options to validate model\")\n",
    "        torch.save(mAP_model.state_dict(), os.path.join(TRAIN_CHECKPOINTS_FOLDER, TRAIN_MODEL_NAME))\n",
    "        continue\n",
    "\n",
    "    count, giou_val, conf_val, prob_val, total_val = 0., 0, 0, 0, 0\n",
    "    for image_data, target in testset:\n",
    "        results = validate_step(image_data, target)\n",
    "        count += 1\n",
    "        giou_val += results[0]\n",
    "        conf_val += results[1]\n",
    "        prob_val += results[2]\n",
    "        total_val += results[3]\n",
    "\n",
    "    with writer.as_default():\n",
    "        writer.add_scalar(\"validate_loss/total_val\", total_val / count, epoch)\n",
    "        writer.add_scalar(\"validate_loss/giou_val\", giou_val / count, epoch)\n",
    "        writer.add_scalar(\"validate_loss/conf_val\", conf_val / count, epoch)\n",
    "        writer.add_scalar(\"validate_loss/prob_val\", prob_val / count, epoch)\n",
    "\n",
    "    writer.flush()\n",
    "\n",
    "    print(\"\\n\\ngiou_val_loss:{:7.2f}, conf_val_loss:{:7.2f}, prob_val_loss:{:7.2f}, total_val_loss:{:7.2f}\\n\\n\".\n",
    "          format(giou_val / count, conf_val / count, prob_val / count, total_val / count))\n",
    "    \n",
    "    if TRAIN_SAVE_CHECKPOINT and not TRAIN_SAVE_BEST_ONLY:\n",
    "        save_directory = os.path.join(TRAIN_CHECKPOINTS_FOLDER, TRAIN_MODEL_NAME + \"_val_loss_{:7.2f}\".format(total_val / count))\n",
    "    torch.save(yolo.state_dict(), save_directory)\n",
    "if TRAIN_SAVE_BEST_ONLY and best_val_loss > total_val / count:\n",
    "    save_directory = os.path.join(TRAIN_CHECKPOINTS_FOLDER, TRAIN_MODEL_NAME)\n",
    "    torch.save(yolo.state_dict(), save_directory)\n",
    "    best_val_loss = total_val / count\n",
    "if not TRAIN_SAVE_BEST_ONLY and not TRAIN_SAVE_CHECKPOINT:\n",
    "    save_directory = os.path.join(TRAIN_CHECKPOINTS_FOLDER, TRAIN_MODEL_NAME)\n",
    "    torch.save(yolo.state_dict(), save_directory)\n",
    "\n",
    "try:\n",
    "    mAP_model.load_state_dict(torch.load(save_directory))\n",
    "    mAP = get_mAP(mAP_model, testset, score_threshold=TEST_SCORE_THRESHOLD, iou_threshold=TEST_IOU_THRESHOLD)\n",
    "    with writer.as_default():\n",
    "        writer.add_scalar(\"validate_mAP\", mAP, epoch)\n",
    "    writer.flush()\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    \n",
    "onnx_filename = \"yolov8.onnx\" \n",
    "dummy_input = torch.randn(1, 3, YOLO_INPUT_SIZE, YOLO_INPUT_SIZE).to(device)\n",
    "torch.onnx.export(yolo, dummy_input, onnx_filename, verbose=True, input_names=['input'], output_names=['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24f9e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f8c9fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
